import os
from datasets import load_dataset
from huggingface_hub import snapshot_download

# é…ç½®è·¯å¾„ (å¿…é¡»ä¸ eval_stage1_v3.py ä¸€è‡´)
PROJECT_ROOT = os.getcwd()
CACHE_DIR = os.path.join(PROJECT_ROOT, "dataset_cache")

os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["HF_HOME"] = CACHE_DIR
os.environ["HF_DATASETS_CACHE"] = CACHE_DIR

# è¿™é‡Œçš„åˆ—è¡¨ä¸åŒ…å« MMLUï¼Œå› ä¸º MMLU ä½ å·²ç»ä¿®å¥½äº†
MISSING_TARGETS = [
    {"name": "ARC", "path": "allenai/ai2_arc", "config": "ARC-Challenge", "split": "test"},
    # {"name": "HellaSwag", "path": "Rowan/hellaswag", "config": None, "split": "validation"},
    {"name": "IFEval", "path": "google/IFEval", "config": None, "split": "train"},
    {"name": "PIQA", "path": "piqa", "config": None, "split": "validation"}
]

print(f"ğŸš€ å¯åŠ¨ç¼ºå£è¡¥å…¨ (ARC/HellaSwag/IFEval/PIQA)...")
print(f"ğŸ“‚ ç¼“å­˜è·¯å¾„: {CACHE_DIR}")

for item in MISSING_TARGETS:
    print(f"\nğŸ‘‰ æ­£åœ¨å¤„ç†: {item['name']} ... ", end="", flush=True)
    try:
        # ç‰¹æ®Šå¤„ç† PIQAï¼šå¦‚æœå¸¸è§„ä¸‹è½½å¤±è´¥ï¼Œç”¨å¿«ç…§
        if item['name'] == "PIQA":
            try:
                load_dataset(item['path'], cache_dir=CACHE_DIR, trust_remote_code=True)
            except:
                print("   [åˆ‡æ¢å¿«ç…§ä¸‹è½½]...", end="", flush=True)
                local_dir = os.path.join(CACHE_DIR, "piqa")
                snapshot_download(repo_id="piqa", repo_type="dataset", local_dir=local_dir, local_dir_use_symlinks=False)
                load_dataset(local_dir, cache_dir=CACHE_DIR, trust_remote_code=True)
        else:
            # å¸¸è§„ä¸‹è½½
            load_dataset(item['path'], item['config'], cache_dir=CACHE_DIR, trust_remote_code=True)
        
        print("âœ… æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å¤±è´¥: {str(e)[:100]}")

print("\nğŸ‰ è¡¥å…¨ä»»åŠ¡ç»“æŸï¼è¯·ç»§ç»­ä¸‹ä¸€æ­¥ã€‚")